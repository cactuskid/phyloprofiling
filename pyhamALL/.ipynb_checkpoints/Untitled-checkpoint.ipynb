{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laurent/anaconda3/lib/python3.6/site-packages/tables/leaf.py:396: PerformanceWarning: The Leaf ``/Protein/_i_Entries/OmaHOG/sorted`` is exceeding the maximum recommended rowsize (104857600 bytes);\n",
      "be ready to see PyTables asking for *lots* of memory and possibly slow\n",
      "I/O.  You may want to reduce the rowsize by trimming the value of\n",
      "dimensions that are orthogonal (and preferably close) to the *main*\n",
      "dimension of this leave.  Alternatively, in case you have specified a\n",
      "very small/large chunksize, you may want to increase/decrease it.\n",
      "  PerformanceWarning)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pyham\n",
    "from pyoma.browser import db \n",
    "import numpy as np\n",
    "from tables import *\n",
    "import re\n",
    "from ete3 import Tree\n",
    "import pickle\n",
    "import tempfile\n",
    "import functools\n",
    "import config\n",
    "\n",
    "import formatOrtho\n",
    "import pyhamPipeline\n",
    "import profileGen\n",
    "\n",
    "from datasketch import MinHashLSH\n",
    "\n",
    "#open up OMA\n",
    "h5file = open_file(config.omadirLaurent + 'OmaServer.h5', mode=\"r\") \n",
    "#setup db objects\n",
    "dbObj = db.Database(h5file)\n",
    "omaIdObj = db.OmaIdMapper(dbObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3711\n",
      "hello\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'0 node(s) founded for the species name: Sulfolobus_islandicus__strain_L_S_2_15_/_Lassen_#1_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c65c1816a724>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mnewortho\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatOrtho\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_orthoxml_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mortho\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplacement_dic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mtreemap_fam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyhamPipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_hamTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdbObj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecies_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplacement_dic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/phylo/phyloprofiling/pyhamALL/pyhamPipeline.py\u001b[0m in \u001b[0;36mget_hamTree\u001b[0;34m(fam, dbObj, species_tree, replacement_dic, l)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mortho\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_orthoxml_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mortho\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplacement_dic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# get ham Object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mhamObj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyham\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspecies_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mortho\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_hog_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"string\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_internal_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mhog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhamObj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_hog_by_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhamObj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_tree_profile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyham/ham.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, newick_str, hog_file, type_hog_file, filter_object, use_internal_name)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhog_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m                 \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_level_hogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextant_gene_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternal_id_mapper\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mfactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoplevel_hogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextant_gene_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternal_id_mapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyham/parsers.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, tag, attrib)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"{http://orthoXML.org/2011/}species\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_species\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mham_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_extant_genome_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mattrib\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"{http://orthoXML.org/2011/}gene\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterObj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyham/ham.py\u001b[0m in \u001b[0;36m_get_extant_genome_by_name\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    786\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mextant_genome\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} node(s) founded for the species name: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes_founded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_ancestral_genome_by_taxon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtax_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '0 node(s) founded for the species name: Sulfolobus_islandicus__strain_L_S_2_15_/_Lassen_#1_'"
     ]
    }
   ],
   "source": [
    "# corrects species tree and replacement dictionary for orthoXML files\n",
    "species_tree, replacement_dic = formatOrtho.fix_species_tree(\"speciestree_corrected.nwk\", omaIdObj)\n",
    "\n",
    "\n",
    "lsh = MinHashLSH()\n",
    "\n",
    "#load Fam\n",
    "for fam in pyhamPipeline.yieldFamilies(h5file):\n",
    "\n",
    "    # generate pyham object\n",
    "    if fam == 3711:\n",
    "        print(fam)\n",
    "        #generate treemap profile\n",
    "        ortho = dbObj.get_orthoxml(fam).decode()\n",
    "        newortho = formatOrtho.convert_orthoxml_ids(ortho, replacement_dic, verbose=True)\n",
    "\n",
    "        treemap_fam = pyhamPipeline.get_hamTree(fam, dbObj, species_tree, replacement_dic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ete3\n",
    "\n",
    "# load species tree in a ete3 tree object\n",
    "t = ete3.Tree(\"speciestree.nwk\", format=1, quoted_node_names=True)\n",
    "\n",
    "for node in t.traverse():\n",
    "    # find the node where the node belongs as a child\n",
    "    if 'Nanohaloarchaea' in node.name:\n",
    "        node.add_child(name='Haloredivivus sp. (strain G17)')\n",
    "\n",
    "# save the corrected tree in a new file\n",
    "with open(config.working_dir + 'speciestree_corrected.nwk' , 'w') as outfile:\n",
    "    outfile.write(t.write(format=1,quoted_node_names=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version='1.0' encoding='UTF-8'?>\n",
      "<orthoXML xmlns=\"http://orthoXML.org/2011/\" origin=\"OMA\" originVersion=\"Nov 2017\" version=\"0.3\">\n",
      "  <species name=\"Sulfolobus solfataricus (strain 98/2)\" NCBITaxId=\"555311\">\n",
      "    <database name=\"Sulfolobus solfataricus (strain 98/2) chromosome, complete sequence.\" version=\"09-FEB-2010 (Rel. 117, Last updated, Version 2)\">\n",
      "      <genes>\n",
      "        <gene id=\"66082\" protId=\"SULS902263\"/>\n",
      "      </genes>\n",
      "    </database>\n",
      "  </species>\n",
      "  <species name=\"Sulfolobus solfataricus (strain ATCC 35092 / DSM 1617 / JCM 11322 / P2)\" NCBITaxId=\"273057\">\n",
      "    <database name=\"Sulfolobus solfataricus (strain DSM 1617 / JCM 11322 / P2 / ATCC 35092) chromosome, complete sequence.\" version=\"01-SEP-2009 (Rel. 110, Last updated, Version 111)\">\n",
      "      <genes>\n",
      "        <gene id=\"68027\" protId=\"SULSO01591\"/>\n",
      "      </genes>\n",
      "    </database>\n",
      "  </species>\n",
      "  <groups>\n",
      "    <orthologGroup id=\"3664\">\n",
      "      <property name=\"TaxRange\" value=\"Sulfolobus solfataricus\"/>\n",
      "      <geneRef id=\"66082\"/>\n",
      "      <geneRef id=\"68027\"/>\n",
      "    </orthologGroup>\n",
      "  </groups>\n",
      "</orthoXML>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ortho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version='1.0' encoding='UTF-8'?>\n",
      "<orthoXML xmlns=\"http://orthoXML.org/2011/\" origin=\"OMA\" originVersion=\"Nov 2017\" version=\"0.3\">\n",
      "  <species name=\"Sulfolobus_solfataricus__strain_98/2_\" NCBITaxId=\"555311\">\n",
      "    <database name=\"Sulfolobus solfataricus (strain 98/2) chromosome, complete sequence.\" version=\"09-FEB-2010 (Rel. 117, Last updated, Version 2)\">\n",
      "      <genes>\n",
      "        <gene id=\"66082\" protId=\"SULS902263\"/>\n",
      "      </genes>\n",
      "    </database>\n",
      "  </species>\n",
      "  <species name=\"Sulfolobus_solfataricus__strain_ATCC_35092_/_DSM_1617_/_JCM_11322_/_P2_\" NCBITaxId=\"273057\">\n",
      "    <database name=\"Sulfolobus solfataricus (strain DSM 1617 / JCM 11322 / P2 / ATCC 35092) chromosome, complete sequence.\" version=\"01-SEP-2009 (Rel. 110, Last updated, Version 111)\">\n",
      "      <genes>\n",
      "        <gene id=\"68027\" protId=\"SULSO01591\"/>\n",
      "      </genes>\n",
      "    </database>\n",
      "  </species>\n",
      "  <groups>\n",
      "    <orthologGroup id=\"3664\">\n",
      "      <property name=\"TaxRange\" value=\"Sulfolobus_solfataricus\"/>\n",
      "      <geneRef id=\"66082\"/>\n",
      "      <geneRef id=\"68027\"/>\n",
      "    </orthologGroup>\n",
      "  </groups>\n",
      "</orthoXML>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newortho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laurent/anaconda3/lib/python3.6/site-packages/tables/leaf.py:396: PerformanceWarning: The Leaf ``/Protein/_i_Entries/OmaHOG/sorted`` is exceeding the maximum recommended rowsize (104857600 bytes);\n",
      "be ready to see PyTables asking for *lots* of memory and possibly slow\n",
      "I/O.  You may want to reduce the rowsize by trimming the value of\n",
      "dimensions that are orthogonal (and preferably close) to the *main*\n",
      "dimension of this leave.  Alternatively, in case you have specified a\n",
      "very small/large chunksize, you may want to increase/decrease it.\n",
      "  PerformanceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "135 can't be used by pyHam: minimum two genomes are required.\n",
      "136\n",
      "137\n",
      "137 can't be used by pyHam: minimum two genomes are required.\n",
      "138\n",
      "139\n",
      "139 can't be used by pyHam: minimum two genomes are required.\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "146 can't be used by pyHam: minimum two genomes are required.\n",
      "147\n",
      "147 can't be used by pyHam: minimum two genomes are required.\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "151 can't be used by pyHam: minimum two genomes are required.\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "155 can't be used by pyHam: minimum two genomes are required.\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "162 can't be used by pyHam: minimum two genomes are required.\n",
      "163\n",
      "164\n",
      "164 can't be used by pyHam: minimum two genomes are required.\n",
      "165\n",
      "166\n",
      "167\n",
      "167 can't be used by pyHam: minimum two genomes are required.\n",
      "168\n",
      "168 can't be used by pyHam: minimum two genomes are required.\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "172 can't be used by pyHam: minimum two genomes are required.\n",
      "173\n",
      "173 can't be used by pyHam: minimum two genomes are required.\n",
      "174\n",
      "175\n",
      "175 can't be used by pyHam: minimum two genomes are required.\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "183 can't be used by pyHam: minimum two genomes are required.\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "189 can't be used by pyHam: minimum two genomes are required.\n",
      "190\n",
      "190 can't be used by pyHam: minimum two genomes are required.\n",
      "191\n",
      "192\n",
      "192 can't be used by pyHam: minimum two genomes are required.\n",
      "193\n",
      "193 can't be used by pyHam: minimum two genomes are required.\n",
      "194\n",
      "195\n",
      "196\n",
      "196 can't be used by pyHam: minimum two genomes are required.\n",
      "197\n",
      "197 can't be used by pyHam: minimum two genomes are required.\n",
      "198\n",
      "198 can't be used by pyHam: minimum two genomes are required.\n",
      "199\n",
      "199 can't be used by pyHam: minimum two genomes are required.\n",
      "200\n",
      "200 can't be used by pyHam: minimum two genomes are required.\n",
      "201\n",
      "201 can't be used by pyHam: minimum two genomes are required.\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "205 can't be used by pyHam: minimum two genomes are required.\n",
      "206\n",
      "207\n",
      "207 can't be used by pyHam: minimum two genomes are required.\n",
      "208\n",
      "209\n",
      "209 can't be used by pyHam: minimum two genomes are required.\n",
      "210\n",
      "211\n",
      "211 can't be used by pyHam: minimum two genomes are required.\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "218 can't be used by pyHam: minimum two genomes are required.\n",
      "219\n",
      "220\n",
      "221\n",
      "221 can't be used by pyHam: minimum two genomes are required.\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "232 can't be used by pyHam: minimum two genomes are required.\n",
      "233\n",
      "233 can't be used by pyHam: minimum two genomes are required.\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "238 can't be used by pyHam: minimum two genomes are required.\n",
      "239\n",
      "239 can't be used by pyHam: minimum two genomes are required.\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "245 can't be used by pyHam: minimum two genomes are required.\n",
      "246\n",
      "246 can't be used by pyHam: minimum two genomes are required.\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "250 can't be used by pyHam: minimum two genomes are required.\n",
      "251\n",
      "252\n",
      "253\n",
      "253 can't be used by pyHam: minimum two genomes are required.\n",
      "254\n",
      "254 can't be used by pyHam: minimum two genomes are required.\n",
      "255\n",
      "255 can't be used by pyHam: minimum two genomes are required.\n",
      "256\n",
      "257\n",
      "257 can't be used by pyHam: minimum two genomes are required.\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "261 can't be used by pyHam: minimum two genomes are required.\n",
      "262\n",
      "262 can't be used by pyHam: minimum two genomes are required.\n",
      "263\n",
      "263 can't be used by pyHam: minimum two genomes are required.\n",
      "264\n",
      "264 can't be used by pyHam: minimum two genomes are required.\n",
      "265\n",
      "266\n",
      "267\n",
      "267 can't be used by pyHam: minimum two genomes are required.\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "272 can't be used by pyHam: minimum two genomes are required.\n",
      "273\n",
      "274\n",
      "275\n",
      "275 can't be used by pyHam: minimum two genomes are required.\n",
      "276\n",
      "277\n",
      "277 can't be used by pyHam: minimum two genomes are required.\n",
      "278\n",
      "279\n",
      "279 can't be used by pyHam: minimum two genomes are required.\n",
      "280\n",
      "280 can't be used by pyHam: minimum two genomes are required.\n",
      "281\n",
      "282\n",
      "282 can't be used by pyHam: minimum two genomes are required.\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n"
     ]
    }
   ],
   "source": [
    "import pyham\n",
    "from pyoma.browser import db \n",
    "import numpy as np\n",
    "from tables import *\n",
    "import re\n",
    "from ete3 import Tree\n",
    "import pickle\n",
    "import tempfile\n",
    "import functools\n",
    "import config\n",
    "\n",
    "import pyhamPipeline\n",
    "import profileGen\n",
    "\n",
    "from datasketch import MinHashLSH\n",
    "\n",
    "# with open( config.working_dir + \"speciestree.nwk\" , 'r') as treefile:\n",
    "#     species_tree = treefile.read()\n",
    "# t = Tree(species_tree, format =1 )\n",
    "# print(t)\n",
    "# #rewrite IDs and reload tree\n",
    "# #\n",
    "# species_tree = pyham.utils.get_newick_string(working_dir + \"speciestree_hack.nwk\", type=\"nwk\")\n",
    "\n",
    "\n",
    "#open up OMA\n",
    "h5file = open_file(config.omadirLaurent + 'OmaServer.h5', mode=\"r\") \n",
    "#setup db objects\n",
    "dbObj = db.Database(h5file)\n",
    "omaIdObj = db.OmaIdMapper(dbObj)\n",
    "\n",
    "# corrects species tree and replacement dictionary for orthoXML files\n",
    "species_tree, replacement_dic = formatOrtho.fix_species_tree(\"speciestree.nwk\", omaIdObj)\n",
    "\n",
    "#temporary, \n",
    "#mat_list = []\n",
    "#dico_list = []\n",
    "lsh = MinHashLSH()\n",
    "\n",
    "#load Fam\n",
    "for fam in pyhamPipeline.yieldFamilies(h5file):\n",
    "\n",
    "    # generate pyham object\n",
    "    if fam > 120:\n",
    "        try:\n",
    "            print(fam)\n",
    "            #generate treemap profile\n",
    "            treemap_fam = pyhamPipeline.get_hamTree(fam, dbObj, species_tree, replacement_dic)\n",
    "            ortho = dbObj.get_orthoxml(fam).decode()\n",
    "            newortho = formatOrtho.convert_orthoxml_ids(ortho, replacement_dic, verbose=True)\n",
    "            # generate matrix of hash\n",
    "            #profileGen.Tree2Hashes(treemap_fam, fam, lsh)\n",
    "            #dico_list.append(dico)\n",
    "\n",
    "            # generate taxa index\n",
    "            #taxaIndex, taxaIndexReverse = profileGen.generateTaxaIndex(species_tree)\n",
    "\n",
    "            # generate matrix of 1 and 0 for each biological event\n",
    "            #profileGen.Tree2mat(treemap_fam, taxaIndex)\n",
    "            #mat_list.append(mat)\n",
    "\n",
    "        except ValueError:\n",
    "            print(\"{} can't be used by pyHam: minimum two genomes are required.\".format(fam))\n",
    "        except KeyError as kerr:\n",
    "            print(\"KeyError: {} at {}\".format(kerr, fam))\n",
    "        except:\n",
    "            print('breaking at fam: {}'.format(fam))\n",
    "    #     if fam > 10000:\n",
    "    #         break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
