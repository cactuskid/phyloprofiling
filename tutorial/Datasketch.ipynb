{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Datasketch</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of probabilistic data structures that can process and search very large amount of data super fast, with little loss of accuracy.\n",
    "\n",
    "This package contains different data sketches: <b>MinHash</b>, Weighted MinHash, HyperLogLog, HyperLogLog++.\n",
    "It also provides different indexes such as <b>MinHash LSH</b>, MinHash LSH Forest and MinHash LSH Ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Install</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install datasketch using <b>pip</b>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-5d01922d3260>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-5d01922d3260>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip install datasketch -U\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install datasketch -U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>MinHash</h2>\n",
    "\n",
    "MinHash is a probabilistic data structure for estimating Jaccard similarity (Intersection over Union) between sets in linear time using a small and fixed memory space.\n",
    "\n",
    "---\n",
    "First, create the MinHash objects for a list or set of items:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasketch import MinHash\n",
    "\n",
    "UNIL = ['UNIL','is','the','best','university','in','Switzerland']\n",
    "EPFL = ['EPFL','is','the','best','university','in','Switzerland']\n",
    "MIT = ['MIT','is','an','average','school','in','usa']\n",
    "\n",
    "minUNIL, minEPFL, minMIT = MinHash(), MinHash(), MinHash()\n",
    "\n",
    "for d in UNIL:\n",
    "    minUNIL.update(d.encode('utf8'))\n",
    "for d in EPFL:\n",
    "    minEPFL.update(d.encode('utf8'))\n",
    "for d in MIT:\n",
    "    minMIT.update(d.encode('utf8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Then, compare the minHashes with the jaccard method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Jaccard for UNIL and EPFL is 0.7421875\n",
      "Actual Jaccard for UNIL and EPFL is 0.75\n"
     ]
    }
   ],
   "source": [
    "print(\"Estimated Jaccard for UNIL and EPFL is\", minUNIL.jaccard(minEPFL))\n",
    "\n",
    "s1 = set(UNIL)\n",
    "s2 = set(EPFL)\n",
    "actual_jaccard = float(len(s1.intersection(s2)))/float(len(s1.union(s2)))\n",
    "print(\"Actual Jaccard for UNIL and EPFL is\", actual_jaccard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Jaccard for UNIL and MIT is 0.1796875\n",
      "Actual Jaccard for UNIL and MIT is 0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "print(\"Estimated Jaccard for UNIL and MIT is\", minUNIL.jaccard(minMIT))\n",
    "\n",
    "s1 = set(UNIL)\n",
    "s3 = set(MIT)\n",
    "actual_jaccard = float(len(s1.intersection(s3)))/float(len(s1.union(s3)))\n",
    "print(\"Actual Jaccard for UNIL and MIT is\", actual_jaccard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "You can adjust the accuracy by customizing the number of permutation functions used in MinHash:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will give better accuracy than the default setting (128).\n",
    "m = MinHash(num_perm=256)\n",
    "\n",
    "minUNIL, minEPFL, minMIT = MinHash(num_perm=256), MinHash(num_perm=256), MinHash(num_perm=256)\n",
    "\n",
    "for d in UNIL:\n",
    "    minUNIL.update(d.encode('utf8'))\n",
    "for d in EPFL:\n",
    "    minEPFL.update(d.encode('utf8'))\n",
    "for d in MIT:\n",
    "    minMIT.update(d.encode('utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Jaccard for UNIL and EPFL is 0.76171875\n",
      "Actual Jaccard for UNIL and EPFL is 0.75\n"
     ]
    }
   ],
   "source": [
    "print(\"Estimated Jaccard for UNIL and EPFL is\", minUNIL.jaccard(minEPFL))\n",
    "\n",
    "s1 = set(UNIL)\n",
    "s2 = set(EPFL)\n",
    "actual_jaccard = float(len(s1.intersection(s2)))/float(len(s1.union(s2)))\n",
    "print(\"Actual Jaccard for UNIL and EPFL is\", actual_jaccard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Jaccard for UNIL and MIT is 0.1640625\n",
      "Actual Jaccard for UNIL and MIT is 0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "print(\"Estimated Jaccard for UNIL and MIT is\", minUNIL.jaccard(minMIT))\n",
    "\n",
    "s1 = set(UNIL)\n",
    "s3 = set(MIT)\n",
    "actual_jaccard = float(len(s1.intersection(s3)))/float(len(s1.union(s3)))\n",
    "print(\"Actual Jaccard for UNIL and MIT is\", actual_jaccard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The trade-off for better accuracy is slower speed and higher memory usage. Indeed, using more permutation functions means more CPU instructions for every data value hashed and more hash values to be stored.\n",
    "\n",
    "---\n",
    "You can union two MinHash objects using the <b>merge</b> function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-cd4f833f5528>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# The makes m1 the union of m2 and the original m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'm1' is not defined"
     ]
    }
   ],
   "source": [
    "# The makes m1 the union of m2 and the original m1.\n",
    "m1.merge(m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "If you are handling a lot of MinHash objects, you can use <b>datasketch.LeanMinHash</b> to reduce your memory footprint.\n",
    "\n",
    "Lean MinHash is MinHash with a smaller memory footprint and faster deserialization, but with its internal state frozen, meaning that it cannot be updated.\n",
    "\n",
    "Lean MinHash inherits all methods from the standard MinHash object. It does not store the permutations and the hashobj needed for updating. If a MinHash does not need further updates, convert it into a lean MinHash to save memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76171875"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasketch import LeanMinHash\n",
    "\n",
    "lean_minEPFL = LeanMinHash(minEPFL)\n",
    "lean_minUNIL = LeanMinHash(minUNIL)\n",
    "\n",
    "# You can compute the Jaccard similarity between two lean MinHash\n",
    "lean_minEPFL.jaccard(lean_minUNIL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76171875"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or between a lean MinHash and a MinHash\n",
    "lean_minEPFL.jaccard(minUNIL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "To create a MinHash from a MinHash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "minUNIL_from_leanMinHash = MinHash(seed=lean_minUNIL.seed, hashvalues=lean_minUNIL.hashvalues)\n",
    "\n",
    "# Or if you want to prevent further updates on minhash\n",
    "# from affecting the state of lean_minhash\n",
    "minUNIL_from_leanMinHash = MinHash(seed=lean_minUNIL.seed, hashvalues=lean_minUNIL.digest())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>MinHash LSH</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you have a very large collection of sets. Giving a query, which is also a set, you want to find sets in your collection that have Jaccard similarities above certain threshold, and you want to do it with many other queries. To do this efficiently, you can create a MinHash for every set, and when a query comes, you compute the Jaccard similarities between the query MinHash and all the MinHash of your collection, and return the sets that satisfy your threshold.\n",
    "\n",
    "This approach is an O(n) algorithm, meaning the query cost increases linearly with respect to the number of sets. A popular alternative is to use Locality Sensitive Hashing (LSH) index. LSH can be used with MinHash to achieve sub-linear query cost - that is a huge improvement. \n",
    "\n",
    "Datasketch includes the classic version of MinHash LSH.\n",
    "\n",
    "---\n",
    "\n",
    "First, insert the minHashes into the LSH:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasketch import MinHashLSH\n",
    "\n",
    "# Create LSH index\n",
    "lsh = MinHashLSH(threshold=0.5, num_perm=256)\n",
    "lsh.insert(\"minUNIL\", minUNIL)\n",
    "lsh.insert(\"minEPFL\", minEPFL)\n",
    "lsh.insert(\"minMIT\", minMIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the LSH can be queried using the <b>query</b> method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate neighbours of UNIL with Jaccard similarity > 0.5 ['minUNIL', 'minEPFL']\n"
     ]
    }
   ],
   "source": [
    "result = lsh.query(minUNIL)\n",
    "print(\"Approximate neighbours of UNIL with Jaccard similarity > 0.5\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate neighbours of MIT with Jaccard similarity > 0.5 ['minMIT']\n"
     ]
    }
   ],
   "source": [
    "result = lsh.query(minMIT)\n",
    "print(\"Approximate neighbours of MIT with Jaccard similarity > 0.5\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Other data structures implemented in Datasketch</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Weighted MinHash</h3>\n",
    "\n",
    "Implementation of a weighted sampling method, where the probability of drawing identical samples for a pair of inputs is equal to their Jaccard similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>HyperLogLog and HyperLogLog++</h3>\n",
    "HyperLogLog is capable of estimating the cardinality (the number of distinct values) of dataset in a single pass, using a small and fixed memory space.\n",
    "\n",
    "HyperLogLog++ is an enhanced version of HyperLogLog by Google. It uses 64-bit hash values instead of the 32-bit used by HyperLogLog and it has a more stable bias correction scheme based on experiments on many datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>MinHash LSH Ensemble</h3>\n",
    "Jaccard similarity is great for measuring resemblance between two sets, however, it can be a biased measure for set intersection, as large sets are penalized. We can use a better measure for intersection, called containment. It is computed as the intersection size divided by the size of one of the set.\n",
    "\n",
    "Similar to MinHash LSH, there is an LSH index implemented in Datasketch for containment search – given a query set, find sets with containment above a certain threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>MinHash LSH Forest</h3>\n",
    "MinHash LSH is useful for threshold queries. However, top-k queries are often more useful in some cases. LSH Forest is a general LSH data structure that makes top-k query possible for many different types of LSH indexes, which include MinHash LSH. I implemented the MinHash LSH Forest, which takes a MinHash data sketch of the query set, and returns the top-k matching sets that have the highest Jaccard similarities with the query set.\n",
    "\n",
    "The interface of datasketch.MinHashLSHForest is similar to datasketch.MinHashLSH, however, it is very important to call index method after adding the keys. Without calling the index method, the keys won’t be searchable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named datasketch",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8c946af4aaf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasketch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMinHash\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMinHashLSH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named datasketch"
     ]
    }
   ],
   "source": [
    "\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "import time\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "index ={}\n",
    "def hash_from_set(setvals, nperm=128):\n",
    "    minhash = MinHash(nperm)\n",
    "    for val in setvals:\n",
    "        minhash.update(val)\n",
    "    return minhash\n",
    "\n",
    "def jaccard( s1, s2):\n",
    "    s1 = set(s1)\n",
    "    s2 = set(s2)\n",
    "    \n",
    "    return float(len(s1.intersection(s2)))/float(len(s1.union(s2)))\n",
    "\n",
    "hashtimes = []\n",
    "lshtimes = []\n",
    "lintimes = []\n",
    "results1 = []\n",
    "results2 = []\n",
    "for n in range( 1,10):\n",
    "\n",
    "    lsh2 = MinHashLSH(threshold=0.7, num_perm=128)\n",
    "    randset = np.random.randint(0,2, size=(n*1000, 500) )\n",
    "    hashes = { i : hash_from_set(set(np.flatnonzero(randset[i,:])) ) for i in range(randset.shape[0])}\n",
    "    sets = {i : set(np.flatnonzero(randset[i,:])) for i in range(randset.shape[0])}\n",
    "    #insert the hashes of the random sets into the LSH\n",
    "    list(map( lambda args: lsh2.insert(args[0],args[1]) , zip(hashes.keys(),hashes.values())))\n",
    "    #10 random queries\n",
    "    for q in list(np.random.randint(0, randset.shape[0] , size=10)):\n",
    "        start = time.clock()\n",
    "        #using the lsh\n",
    "        result_rows = lsh2.query(hashes[q])\n",
    "        lshtimes.append([n*1000,time.clock()-start])\n",
    "        start = time.clock()\n",
    "        #using a linear search over all of the hashes\n",
    "        hashjaccard = [ hashes[q].jaccard(hashes[i]) for i in range(randset.shape[0]) ]\n",
    "        sortedscores = np.argsort(hashjaccard)[::-1]\n",
    "        hashtimes.append([n*1000,time.clock()-start])\n",
    "        \n",
    "        \n",
    "        print(sorted(result_rows))\n",
    "        print(sorted(list(sortedscores[:len(result_rows)])))\n",
    "        #top 100 entries vs returned results\n",
    "        score1 = jaccard(result_rows,sortedscores[:100])\n",
    "        score2 = jaccard(result_rows,sortedscores[:len(result_rows)])\n",
    "        \n",
    "        print(score1)\n",
    "        print(score2)\n",
    "        \n",
    "        results1.append([score1 , n*1000])\n",
    "        results2.append([score2 , n*1000])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linsearch vs lsh\n",
      "jaccard of results vs n elements\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt\n",
    "hashtimes = np.asarray(hashtimes)\n",
    "lshtimes = np.asarray(lshtimes)\n",
    "print('linsearch vs lsh')\n",
    "plt.scatter(hashtimes[:,0],hashtimes[:,1] )\n",
    "plt.scatter(lshtimes[:,0], lshtimes[:,1])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('jaccard of results vs n elements')\n",
    "\n",
    "#plt.scatter(results1[0], results1[1])\n",
    "#plt.scatter(results2[0], results2[1])\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
